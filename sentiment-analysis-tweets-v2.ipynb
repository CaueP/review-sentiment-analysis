{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare dataset\n",
    "Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data files\n",
    "dataset = pd.read_csv('data/portuguese_tweets.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                   8199\n",
       "Created At                   8199\n",
       "Text                         8199\n",
       "Geo Coordinates.latitude      104\n",
       "Geo Coordinates.longitude     104\n",
       "User Location                5489\n",
       "Username                     8199\n",
       "User Screen Name             8199\n",
       "Retweet Count                8199\n",
       "Classificacao                8199\n",
       "Observação                      1\n",
       "Unnamed: 10                     0\n",
       "Unnamed: 11                     0\n",
       "Unnamed: 12                     0\n",
       "Unnamed: 13                     0\n",
       "Unnamed: 14                     0\n",
       "Unnamed: 15                     0\n",
       "Unnamed: 16                     0\n",
       "Unnamed: 17                     0\n",
       "Unnamed: 18                     0\n",
       "Unnamed: 19                     0\n",
       "Unnamed: 20                     0\n",
       "Unnamed: 21                     0\n",
       "Unnamed: 22                     0\n",
       "Unnamed: 23                     0\n",
       "Unnamed: 24                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate tweets and labels\n",
    "train_documents = dataset['Text'].values\n",
    "train_labels = dataset['Classificacao'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data model\n",
    "vectorizer = CountVectorizer(analyzer=\"word\", binary=True)\n",
    "train_documents = vectorizer.fit_transform(train_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Model Training\n",
    "# classifier = MultinomialNB().fit(train_documents, train_labels)\n",
    "classifier = BernoulliNB().fit(train_documents, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.884620075619\n"
     ]
    }
   ],
   "source": [
    "# Cross validation\n",
    "cross_val_results = cross_val_predict(classifier, train_documents, train_labels, cv=10)\n",
    "# Measuring avg accuracy\n",
    "accuracy = metrics.accuracy_score(train_labels,cross_val_results)\n",
    "print('Accuracy: {}'.format(accuracy))\n",
    "# Accuracy = (TP +TN )/ (TP + FP +TN +FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction  Negativo  Neutro  Positivo   All\n",
      "Real                                        \n",
      "Negativo        2208     224        14  2446\n",
      "Neutro           133    2145       175  2453\n",
      "Positivo          38     362      2900  3300\n",
      "All             2379    2731      3089  8199\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "# assert len(train_labels) == len(cross_val_results)\n",
    "print (pd.crosstab(train_labels, cross_val_results, rownames=['Real'], colnames=['Prediction'], margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Positivo       0.94      0.88      0.91      3300\n",
      "   Negativo       0.93      0.90      0.92      2446\n",
      "     Neutro       0.79      0.87      0.83      2453\n",
      "\n",
      "avg / total       0.89      0.88      0.89      8199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model validation\n",
    "sentimento=['Positivo','Negativo','Neutro']\n",
    "print (metrics.classification_report(train_labels, cross_val_results, sentimento))\n",
    "# precision = true positive / (true positive + false positive)\n",
    "# recall = true positive / (true positive + false negative)\n",
    "# f1-score = 2*((precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(review):\n",
    "    classified = classifier.predict(vectorizer.transform([review]))\n",
    "    return classified[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Neutro'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demo: Neutral review\n",
    "classify_review('Esse governo está no início, vamos ver o que vai dar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Positivo'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demo: Positive review\n",
    "\n",
    "classify_review(\n",
    "    'O Brasil está investindo em educação, construindo mais escolas e preparando melhor os professores'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Negativo'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demo: Negative review\n",
    "classify_review('O Neymar está deixando a desejar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Positivo'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demo: Negative review\n",
    "classify_review('O Brasil voltou, 20 anos em 2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
